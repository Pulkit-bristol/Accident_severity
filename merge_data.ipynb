{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I want to check how all the data is related to each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read the dataframes \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44740, 38)\n",
      "(80224, 46)\n",
      "(114486, 22)\n"
     ]
    }
   ],
   "source": [
    "accident = pd.read_csv(\"cleaned_data/accident.csv\")\n",
    "person = pd.read_csv(\"cleaned_data/person.csv\")\n",
    "vehicle = pd.read_csv(\"cleaned_data/vehicle.csv\")\n",
    "\n",
    "print(accident.shape)\n",
    "print(vehicle.shape)\n",
    "print(person.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accident details\n",
      "     CASENUM  HOUR_I  MINUTE_I  RELJCT_I  ALIGN_I  PROFIL_I  SURCON_I  \\\n",
      "0  110215644      22        23         0        1         2         1   \n",
      "\n",
      "   TRFCON_I  LGTCON_I  WEATHR_I  ...  NON_INVL  NUM_INJ  PED_ACC  PJ  PSU  \\\n",
      "0         0         2         1  ...         0        0        0   2    2   \n",
      "\n",
      "   SPD_LIM  VEH_INVL  YEAR  NO_INJ_I  ALCHL_I  \n",
      "0       99         1  2001         0        2  \n",
      "\n",
      "[1 rows x 38 columns]\n"
     ]
    }
   ],
   "source": [
    "# let's pick one case number\n",
    "\n",
    "# lets pick a particular case number 110215644\n",
    "print(\"Accident details\")\n",
    "print(accident[(accident.CASENUM == 110215644)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________\n",
      "Person Details for this case number\n",
      "     CASENUM  PERNO  VEHNO  AGE_H  SEX_H  INJSEV_H  PERALC_H  WEIGHT  \\\n",
      "0  110215644      1      1     46      2         0         1  271.46   \n",
      "1  110215644      2      1     70      2         0         0  271.46   \n",
      "\n",
      "   PER_TYPE  SEAT_POS  ...  HOSPITAL  PER_ALCH  LOCATN  REST_SYS  IMPAIRMT  \\\n",
      "0         1        11  ...         0         1       0         1         0   \n",
      "1         2        13  ...         0         0       0         1         0   \n",
      "\n",
      "   ACTION  SAF_EQMT  AIRBAG  REGION  PJ  \n",
      "0       0         0       9       1   2  \n",
      "1       0         0       9       1   2  \n",
      "\n",
      "[2 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"____________________\")\n",
    "print(\"Person Details for this case number\")\n",
    "print(person[(person.CASENUM == 110215644)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________\n",
      "Vehicle Details for this case number\n",
      "     CASENUM  WEIGHT  HAZM_NO  MODEL_YR  DAM_AREA  DR_ZIP_C  C_ID_NO  REGION  \\\n",
      "0  110215644  271.46        0      2000     13000     12456        0       1   \n",
      "\n",
      "   HIT_RUN  MAKE  ...  OCC_INVL  PJ  PSU  P_CRASH2  SPEED  VEHNO  IMPACT_H  \\\n",
      "0        0    49  ...         2   2    2        87    999      1         1   \n",
      "\n",
      "   MDLYR_I  MXVSEV_I  V_ALCH_I  \n",
      "0     2000         0         2  \n",
      "\n",
      "[1 rows x 46 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"____________________\")\n",
    "print(\"Vehicle Details for this case number\")\n",
    "print(vehicle[(vehicle.CASENUM == 110215644)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this case case number = 110215644, there was only a single vehicle involved 2 individuals "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's try to analyze for this case number 160325515"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accident details\n",
      "         CASENUM  HOUR_I  MINUTE_I  RELJCT_I  ALIGN_I  PROFIL_I  SURCON_I  \\\n",
      "34941  160325515      16        50         0        1         2         3   \n",
      "\n",
      "       TRFCON_I  LGTCON_I  WEATHR_I  ...  NON_INVL  NUM_INJ  PED_ACC  PJ  PSU  \\\n",
      "34941         0         1         4  ...         0        8        0   1   11   \n",
      "\n",
      "       SPD_LIM  VEH_INVL  YEAR  NO_INJ_I  ALCHL_I  \n",
      "34941       70        23  2001         8        2  \n",
      "\n",
      "[1 rows x 38 columns]\n"
     ]
    }
   ],
   "source": [
    "# let's pick one case number\n",
    "\n",
    "# accident will have a single row for sure\n",
    "# lets pick a particular case number 160325515\n",
    "print(\"Accident details\")\n",
    "print(accident[(accident.CASENUM == 160325515)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________\n",
      "Person Details for this case number\n",
      "         CASENUM  PERNO  VEHNO  AGE_H  SEX_H  INJSEV_H  PERALC_H  WEIGHT  \\\n",
      "89982  160325515      1      1     58      1         0         1  19.051   \n",
      "89983  160325515      1      2     49      1         0         1  19.051   \n",
      "89984  160325515      1      3     23      2         0         1  19.051   \n",
      "89985  160325515      1      4     38      1         0         1  19.051   \n",
      "89986  160325515      1      5     23      2         0         1  19.051   \n",
      "89987  160325515      1      6     46      1         0         1  19.051   \n",
      "89988  160325515      1      7     22      2         2         1  19.051   \n",
      "89989  160325515      1      8     48      2         1         1  19.051   \n",
      "89990  160325515      1      9     35      1         0         1  19.051   \n",
      "89991  160325515      1     10     55      1         0         1  19.051   \n",
      "89992  160325515      1     11     57      1         0         1  19.051   \n",
      "89993  160325515      1     12     57      1         0         1  19.051   \n",
      "89994  160325515      1     13     62      1         1         1  19.051   \n",
      "89995  160325515      1     14     27      2         1         1  19.051   \n",
      "89996  160325515      1     15     57      1         1         1  19.051   \n",
      "89997  160325515      1     16     44      2         1         1  19.051   \n",
      "89998  160325515      1     17     71      1         0         1  19.051   \n",
      "89999  160325515      1     18     61      2         1         1  19.051   \n",
      "90000  160325515      1     19     52      2         1         1  19.051   \n",
      "90001  160325515      1     20     63      2         0         1  19.051   \n",
      "90002  160325515      1     21     25      2         0         1  19.051   \n",
      "90003  160325515      1     22     48      2         0         1  19.051   \n",
      "90004  160325515      1     23     47      1         0         1  19.051   \n",
      "\n",
      "       PER_TYPE  SEAT_POS  ...  HOSPITAL  PER_ALCH  LOCATN  REST_SYS  \\\n",
      "89982         1        11  ...         0         1       0         1   \n",
      "89983         1        11  ...         0         1       0         1   \n",
      "89984         1        11  ...         0         1       0         1   \n",
      "89985         1        11  ...         0         1       0         1   \n",
      "89986         1        11  ...         0         1       0         1   \n",
      "89987         1        11  ...         0         1       0         1   \n",
      "89988         1        11  ...         1         1       0         1   \n",
      "89989         1        11  ...         1         1       0         1   \n",
      "89990         1        11  ...         0         1       0         1   \n",
      "89991         1        11  ...         0         1       0         1   \n",
      "89992         1        11  ...         0         1       0         1   \n",
      "89993         1        11  ...         9         8       0         9   \n",
      "89994         1        11  ...         0         1       0         2   \n",
      "89995         1        11  ...         0         1       0         2   \n",
      "89996         1        11  ...         1         1       0         9   \n",
      "89997         1        11  ...         0         1       0         1   \n",
      "89998         1        11  ...         0         1       0         1   \n",
      "89999         1        11  ...         0         1       0         1   \n",
      "90000         1        11  ...         0         1       0         1   \n",
      "90001         1        11  ...         0         1       0         1   \n",
      "90002         1        11  ...         0         1       0         1   \n",
      "90003         1        11  ...         0         1       0         1   \n",
      "90004         1        11  ...         0         1       0         1   \n",
      "\n",
      "       IMPAIRMT  ACTION  SAF_EQMT  AIRBAG  REGION  PJ  \n",
      "89982         0       0         0       2       2   1  \n",
      "89983         0       0         0       2       2   1  \n",
      "89984         0       0         0       0       2   1  \n",
      "89985         0       0         0       0       2   1  \n",
      "89986         0       0         0       1       2   1  \n",
      "89987         0       0         0       0       2   1  \n",
      "89988         0       0         0       1       2   1  \n",
      "89989         0       0         0       1       2   1  \n",
      "89990         0       0         0       0       2   1  \n",
      "89991         0       0         0       0       2   1  \n",
      "89992         0       0         0       2       2   1  \n",
      "89993        99       0         0       9       2   1  \n",
      "89994         0       0         0       0       2   1  \n",
      "89995         0       0         0       2       2   1  \n",
      "89996         0       0         0       2       2   1  \n",
      "89997         0       0         0       2       2   1  \n",
      "89998         0       0         0       0       2   1  \n",
      "89999         0       0         0       2       2   1  \n",
      "90000         0       0         0       2       2   1  \n",
      "90001         0       0         0       2       2   1  \n",
      "90002         0       0         0       1       2   1  \n",
      "90003         0       0         0       2       2   1  \n",
      "90004         0       0         0       0       2   1  \n",
      "\n",
      "[23 rows x 22 columns]\n",
      "(23, 22)\n"
     ]
    }
   ],
   "source": [
    "print(\"____________________\")\n",
    "print(\"Person Details for this case number\")\n",
    "print(person[(person.CASENUM == 160325515)])\n",
    "print(person[(person.CASENUM == 160325515)].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________\n",
      "Vehicle Details for this case number\n",
      "         CASENUM  WEIGHT  HAZM_NO  MODEL_YR  DAM_AREA  DR_ZIP_C  C_ID_NO  \\\n",
      "62598  160325515  19.051        0      1997     10000     49234        0   \n",
      "62599  160325515  19.051        0      1994     10000     53209        0   \n",
      "62600  160325515  19.051        0      1991     10000     49002        0   \n",
      "62601  160325515  19.051        0      2001     40000     78840   658570   \n",
      "62602  160325515  19.051        0      2000     40000     49201        0   \n",
      "62603  160325515  19.051        0      1999     40000     60433   146880   \n",
      "62604  160325515  19.051        0      1999     10000     48170        0   \n",
      "62605  160325515  19.051        0      1997     10000     49001        0   \n",
      "62606  160325515  19.051        0      1992     20000     48504        0   \n",
      "62607  160325515  19.051        0      1995     10000     63351   438719   \n",
      "62608  160325515  19.051        0      1997     34000     49201        0   \n",
      "62609  160325515  19.051     9999      9999     99999     99999   999999   \n",
      "62610  160325515  19.051        0      1982     20000     49202        0   \n",
      "62611  160325515  19.051        0      1995     24000     49202        0   \n",
      "62612  160325515  19.051        0      2000     40000     35565        0   \n",
      "62613  160325515  19.051        0      1995     40000     49240        0   \n",
      "62614  160325515  19.051        0      1997     34000     67864   139495   \n",
      "62615  160325515  19.051        0      1999     40000     49259        0   \n",
      "62616  160325515  19.051        0      2000     40000     49203        0   \n",
      "62617  160325515  19.051        0      1996     30000     49201        0   \n",
      "62618  160325515  19.051        0      1991     10000     49085        0   \n",
      "62619  160325515  19.051        0      1993     40000     49240        0   \n",
      "62620  160325515  19.051        0      1986     40000     60045        0   \n",
      "\n",
      "       REGION  HIT_RUN  MAKE  ...  OCC_INVL  PJ  PSU  P_CRASH2  SPEED  VEHNO  \\\n",
      "62598       2        0    18  ...         1   1   11        99    999      1   \n",
      "62599       2        0     6  ...         1   1   11        99    999      2   \n",
      "62600       2        0    12  ...         1   1   11        99    999      3   \n",
      "62601       2        0    82  ...         1   1   11        99    999      4   \n",
      "62602       2        0     7  ...         1   1   11        99    999      5   \n",
      "62603       2        0    86  ...         1   1   11        99    999      6   \n",
      "62604       2        0    23  ...         1   1   11        99    999      7   \n",
      "62605       2        0    37  ...         1   1   11        99    999      8   \n",
      "62606       2        0     9  ...         1   1   11        99    999      9   \n",
      "62607       2        0    23  ...         1   1   11        99    999     10   \n",
      "62608       2        0    20  ...         1   1   11        99    999     11   \n",
      "62609       2        0    99  ...         1   1   11        99    999     12   \n",
      "62610       2        0    21  ...         1   1   11        99    999     13   \n",
      "62611       2        0    20  ...         1   1   11        99    999     14   \n",
      "62612       2        0    12  ...         1   1   11        99    999     15   \n",
      "62613       2        0     9  ...         1   1   11        99    999     16   \n",
      "62614       2        0    85  ...         1   1   11        99    999     17   \n",
      "62615       2        0     7  ...         1   1   11        99    999     18   \n",
      "62616       2        0    20  ...         1   1   11        99    999     19   \n",
      "62617       2        0    24  ...         1   1   11        99    999     20   \n",
      "62618       2        0     7  ...         1   1   11        99    999     21   \n",
      "62619       2        0    12  ...         1   1   11        99    999     22   \n",
      "62620       2        0    12  ...         1   1   11        99    999     23   \n",
      "\n",
      "       IMPACT_H  MDLYR_I  MXVSEV_I  V_ALCH_I  \n",
      "62598         1     1997         0         2  \n",
      "62599         4     1994         0         2  \n",
      "62600         4     1991         0         2  \n",
      "62601         4     2001         0         2  \n",
      "62602         4     2000         0         2  \n",
      "62603         4     1999         0         2  \n",
      "62604         4     1999         2         2  \n",
      "62605         4     1997         1         2  \n",
      "62606         2     1992         0         2  \n",
      "62607         4     1995         0         2  \n",
      "62608         4     1997         0         2  \n",
      "62609         2     1982         0         2  \n",
      "62610         2     1982         1         2  \n",
      "62611         4     1995         1         2  \n",
      "62612         4     2000         1         2  \n",
      "62613         4     1995         1         2  \n",
      "62614         4     1997         0         2  \n",
      "62615         4     1999         1         2  \n",
      "62616         4     2000         1         2  \n",
      "62617         3     1996         0         2  \n",
      "62618         4     1991         0         2  \n",
      "62619         4     1993         0         2  \n",
      "62620         4     1986         0         2  \n",
      "\n",
      "[23 rows x 46 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"____________________\")\n",
    "print(\"Vehicle Details for this case number\")\n",
    "print(vehicle[(vehicle.CASENUM == 160325515)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question:- Can there be multiple case number in accident data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for accident we have a single CASENUMBER for particlar \n",
    "(accident.CASENUM.value_counts() > 1).any()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer - No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check the same for vehicle \n",
    "# I am assuming that for a case number there can be multiple vehicle involved\n",
    "\n",
    "(vehicle.CASENUM.value_counts() > 1).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_cases = vehicle.CASENUM.value_counts()\n",
    "duplicate_cases = duplicate_cases[duplicate_cases > 1]  # Filter cases with count > 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CASENUM\n",
       "160325515    23\n",
       "130236944    10\n",
       "180809192     9\n",
       "162917987     9\n",
       "132460321     8\n",
       "             ..\n",
       "122275543     2\n",
       "130245938     2\n",
       "122275465     2\n",
       "130235824     2\n",
       "130235513     2\n",
       "Name: count, Length: 30568, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicate_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________\n",
      "Person Details for this case number\n",
      "         CASENUM  PERNO  VEHNO  AGE_H  SEX_H  INJSEV_H  PERALC_H  WEIGHT  \\\n",
      "30808  130236944      1      1     42      1         0         1   2.701   \n",
      "30809  130236944      1      2     23      1         4         1   2.701   \n",
      "30810  130236944      1      3     19      2         1         1   2.701   \n",
      "30811  130236944      2      3     17      2         1         0   2.701   \n",
      "30812  130236944      1      4     48      1         2         1   2.701   \n",
      "30813  130236944      1      5     20      2         1         1   2.701   \n",
      "30814  130236944      1      6     50      1         0         1   2.701   \n",
      "30815  130236944      1      7     20      1         1         1   2.701   \n",
      "30816  130236944      2      7     41      1         1         0   2.701   \n",
      "30817  130236944      1      8     52      2         2         1   2.701   \n",
      "30818  130236944      1      9     52      2         2         1   2.701   \n",
      "30819  130236944      2      9     18      2         2         0   2.701   \n",
      "30820  130236944      3      9     15      2         2         0   2.701   \n",
      "30821  130236944      1     10     31      2         1         1   2.701   \n",
      "30822  130236944      2     10      9      2         1         0   2.701   \n",
      "30823  130236944      3     10      1      2         1         0   2.701   \n",
      "\n",
      "       PER_TYPE  SEAT_POS  ...  HOSPITAL  PER_ALCH  LOCATN  REST_SYS  \\\n",
      "30808         1        11  ...         0         8       0         9   \n",
      "30809         1        11  ...         0         1       0         1   \n",
      "30810         1        11  ...         1         1       0         1   \n",
      "30811         2        13  ...         1         0       0         1   \n",
      "30812         1        11  ...         1         1       0         5   \n",
      "30813         1        11  ...         1         1       0         1   \n",
      "30814         1        11  ...         0         1       0         1   \n",
      "30815         1        11  ...         0         1       0         2   \n",
      "30816         2        13  ...         0         0       0         1   \n",
      "30817         1        11  ...         1         1       0         0   \n",
      "30818         1        11  ...         1         1       0         1   \n",
      "30819         2        13  ...         1         0       0         1   \n",
      "30820         2        23  ...         1         0       0         1   \n",
      "30821         1        11  ...         1         1       0         1   \n",
      "30822         2        13  ...         0         0       0         1   \n",
      "30823         2        23  ...         1         0       0         6   \n",
      "\n",
      "       IMPAIRMT  ACTION  SAF_EQMT  AIRBAG  REGION  PJ  \n",
      "30808         0       0         0       0       2   4  \n",
      "30809         0       0         0       1       2   4  \n",
      "30810         0       0         0       2       2   4  \n",
      "30811         0       0         0       2       2   4  \n",
      "30812         0       0         0       0       2   4  \n",
      "30813         0       0         0       0       2   4  \n",
      "30814         0       0         0       0       2   4  \n",
      "30815         0       0         0       0       2   4  \n",
      "30816         0       0         0       0       2   4  \n",
      "30817         0       0         0       1       2   4  \n",
      "30818         0       0         0       1       2   4  \n",
      "30819         0       0         0       1       2   4  \n",
      "30820         0       0         0       0       2   4  \n",
      "30821         0       0         0       1       2   4  \n",
      "30822         0       0         0       2       2   4  \n",
      "30823         0       0         0       0       2   4  \n",
      "\n",
      "[16 rows x 22 columns]\n",
      "(16, 22)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"____________________\")\n",
    "print(\"Person Details for this case number\")\n",
    "print(person[(person.CASENUM == 130236944)])\n",
    "print(person[(person.CASENUM == 130236944)].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________\n",
      "Vehicle Details for this case number\n",
      "         CASENUM  WEIGHT  HAZM_NO  MODEL_YR  DAM_AREA  DR_ZIP_C  C_ID_NO  \\\n",
      "21367  130236944   2.701        0      1988     19999     48186   994131   \n",
      "21368  130236944   2.701        0      1993     39999     48125        0   \n",
      "21369  130236944   2.701        0      1983     19999     48180        0   \n",
      "21370  130236944   2.701        0      2001     39999     48146        0   \n",
      "21371  130236944   2.701        0      1990     12999     48125        0   \n",
      "21372  130236944   2.701        0      1989     19999     48180        0   \n",
      "21373  130236944   2.701        0      1990     13999     48179        0   \n",
      "21374  130236944   2.701        0      1994     19999     48188        0   \n",
      "21375  130236944   2.701        0      2000     13999     48126        0   \n",
      "21376  130236944   2.701        0      1991     10000     48101        0   \n",
      "\n",
      "       REGION  HIT_RUN  MAKE  ...  OCC_INVL  PJ  PSU  P_CRASH2  SPEED  VEHNO  \\\n",
      "21367       2        0    85  ...         1   4   10        17    999      1   \n",
      "21368       2        0    12  ...         1   4   10        66    999      2   \n",
      "21369       2        0    20  ...         2   4   10        78      0      3   \n",
      "21370       2        0    37  ...         1   4   10        78      0      4   \n",
      "21371       2        0    12  ...         1   4   10        78      0      5   \n",
      "21372       2        0    20  ...         1   4   10        78      0      6   \n",
      "21373       2        0     7  ...         2   4   10        78      0      7   \n",
      "21374       2        0    58  ...         1   4   10        78      0      8   \n",
      "21375       2        0    20  ...         3   4   10        78      0      9   \n",
      "21376       2        0    12  ...         3   4   10        78      0     10   \n",
      "\n",
      "       IMPACT_H  MDLYR_I  MXVSEV_I  V_ALCH_I  \n",
      "21367         1     1988         0         2  \n",
      "21368         3     1993         4         2  \n",
      "21369         1     1983         1         2  \n",
      "21370         3     2001         2         2  \n",
      "21371         1     1990         1         2  \n",
      "21372         1     1989         0         2  \n",
      "21373         1     1990         1         2  \n",
      "21374         1     1994         2         2  \n",
      "21375         1     2000         2         2  \n",
      "21376         1     1991         1         2  \n",
      "\n",
      "[10 rows x 46 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"____________________\")\n",
    "print(\"Vehicle Details for this case number\")\n",
    "print(vehicle[(vehicle.CASENUM == 130236944)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Ok let's try to merge the data now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common columns: ['WEIGHT', 'PJ', 'CASENUM', 'PSU', 'REGION']\n"
     ]
    }
   ],
   "source": [
    "# we'll merge accident and vehicle data\n",
    "\n",
    "common_columns = list(set(accident.columns) & set(vehicle.columns))\n",
    "\n",
    "# Print the common columns\n",
    "print(\"Common columns:\", common_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common columns: ['CASENUM', 'WEIGHT', 'PJ', 'REGION']\n"
     ]
    }
   ],
   "source": [
    "# we'll merge accident and vehicle data\n",
    "\n",
    "common_columns = list(set(accident.columns) & set(person.columns))\n",
    "\n",
    "# Print the common columns\n",
    "print(\"Common columns:\", common_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common columns: ['WEIGHT', 'PJ', 'CASENUM', 'VEHNO', 'REGION']\n"
     ]
    }
   ],
   "source": [
    "# we'll merge accident and vehicle data\n",
    "\n",
    "common_columns = list(set(vehicle.columns) & set(person.columns))\n",
    "\n",
    "# Print the common columns\n",
    "print(\"Common columns:\", common_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Region column analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [CASENUM, REGION]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "\"\"\"print(vehicle[(vehicle.CASENUM == 160325515)]['PSU'].unique())\n",
    "print(accident[(accident.CASENUM == 160325515)]['PSU'].unique())\n",
    "\n",
    "\n",
    "print(vehicle[(vehicle.CASENUM == 160325515)]['PJ'].unique())\n",
    "print(accident[(accident.CASENUM == 160325515)]['PJ'].unique())\n",
    "\n",
    "print(vehicle[(vehicle.CASENUM == 160325515)]['REGION'].unique())\n",
    "print(accident[(accident.CASENUM == 160325515)]['REGION'].unique())\n",
    "\"\"\"\n",
    "accident_sample = accident[[\"CASENUM\",\"REGION\"]]\n",
    "vehicle_sample = vehicle[[\"CASENUM\",\"REGION\"]]\n",
    "\n",
    "# Group vehicle_sample by 'CASENUM' and stack the 'REGION' values into a list\n",
    "grouped_vehicle_sample = vehicle_sample.groupby('CASENUM')['REGION'].agg(lambda x: set(x)).reset_index()\n",
    "\n",
    "# Display the result\n",
    "#print(grouped_vehicle_sample)\n",
    "\n",
    "# Filter rows where the length of the 'REGION' set is greater than 1\n",
    "multiple_regions = grouped_vehicle_sample[grouped_vehicle_sample['REGION'].apply(len) > 1]\n",
    "\n",
    "# Display the result\n",
    "print(multiple_regions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PJ column analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [CASENUM, PJ]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "\n",
    "accident_sample = accident[[\"CASENUM\",\"PJ\"]]\n",
    "vehicle_sample = vehicle[[\"CASENUM\",\"PJ\"]]\n",
    "\n",
    "# Group vehicle_sample by 'CASENUM' and stack the 'REGION' values into a list\n",
    "grouped_vehicle_sample = vehicle_sample.groupby('CASENUM')['PJ'].agg(lambda x: set(x)).reset_index()\n",
    "\n",
    "# Display the result\n",
    "#print(grouped_vehicle_sample)\n",
    "\n",
    "# Filter rows where the length of the 'REGION' set is greater than 1\n",
    "multiple_regions = grouped_vehicle_sample[grouped_vehicle_sample['PJ'].apply(len) > 1]\n",
    "\n",
    "# Display the result\n",
    "print(multiple_regions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PSU column analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [CASENUM, PSU]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "\n",
    "accident_sample = accident[[\"CASENUM\",\"PSU\"]]\n",
    "vehicle_sample = vehicle[[\"CASENUM\",\"PSU\"]]\n",
    "\n",
    "# Group vehicle_sample by 'CASENUM' and stack the 'REGION' values into a list\n",
    "grouped_vehicle_sample = vehicle_sample.groupby('CASENUM')['PSU'].agg(lambda x: set(x)).reset_index()\n",
    "\n",
    "# Display the result\n",
    "#print(grouped_vehicle_sample)\n",
    "\n",
    "# Filter rows where the length of the 'REGION' set is greater than 1\n",
    "multiple_regions = grouped_vehicle_sample[grouped_vehicle_sample['PSU'].apply(len) > 1]\n",
    "\n",
    "# Display the result\n",
    "print(multiple_regions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so in vehicle and accident data ['PSU', 'REGION', 'PJ', 'WEIGHT', 'CASENUM'] columns resembles the same values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80224, 79)\n"
     ]
    }
   ],
   "source": [
    "# taking accident on left and vehicle on right we can do a left join on ['PSU', 'REGION', 'PJ', 'WEIGHT', 'CASENUM'] these columns \n",
    "\n",
    "# Perform a left join on the specified columns\n",
    "merged_data_accident_vehicle = pd.merge(accident, vehicle, on=['PSU', 'REGION', 'PJ', 'WEIGHT', 'CASENUM'], how='left')\n",
    "\n",
    "print(merged_data_accident_vehicle.shape)\n",
    "# Display the result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_accident_vehicle.to_csv(\"cleaned_data/merged_data_accident_vehicle.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# check for null values\n",
    "t1 = tuple(zip(list(merged_data_accident_vehicle.columns),list(merged_data_accident_vehicle.isna().sum())))\n",
    "print([(col, missing) for col, missing in t1 if missing > 0])\n",
    "\n",
    "\n",
    "# There are no null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## we have 80224 rows which is equal to vehicle shape, thus we can say that the data was joined completely without anything left in the vehicles dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we need to merge the `merged_data_accident_vehicle` with `person` table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common columns: ['WEIGHT', 'PJ', 'CASENUM', 'VEHNO', 'REGION']\n"
     ]
    }
   ],
   "source": [
    "# we'll merge accident and vehicle data\n",
    "\n",
    "common_columns = list(set(merged_data_accident_vehicle.columns) & set(person.columns))\n",
    "\n",
    "# Print the common columns\n",
    "print(\"Common columns:\", common_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [CASENUM, PJ]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "\n",
    "accident_sample = merged_data_accident_vehicle[[\"CASENUM\",\"PJ\"]]\n",
    "vehicle_sample = person[[\"CASENUM\",\"PJ\"]]\n",
    "\n",
    "# Group vehicle_sample by 'CASENUM' and stack the 'REGION' values into a list\n",
    "grouped_vehicle_sample = vehicle_sample.groupby('CASENUM')['PJ'].agg(lambda x: set(x)).reset_index()\n",
    "\n",
    "# Display the result\n",
    "#print(grouped_vehicle_sample)\n",
    "\n",
    "# Filter rows where the length of the 'REGION' set is greater than 1\n",
    "multiple_regions = grouped_vehicle_sample[grouped_vehicle_sample['PJ'].apply(len) > 1]\n",
    "\n",
    "# Display the result\n",
    "print(multiple_regions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [CASENUM, REGION]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "\n",
    "accident_sample = merged_data_accident_vehicle[[\"CASENUM\",\"REGION\"]]\n",
    "vehicle_sample = person[[\"CASENUM\",\"REGION\"]]\n",
    "\n",
    "# Group vehicle_sample by 'CASENUM' and stack the 'REGION' values into a list\n",
    "grouped_vehicle_sample = vehicle_sample.groupby('CASENUM')['REGION'].agg(lambda x: set(x)).reset_index()\n",
    "\n",
    "# Display the result\n",
    "#print(grouped_vehicle_sample)\n",
    "\n",
    "# Filter rows where the length of the 'REGION' set is greater than 1\n",
    "multiple_regions = grouped_vehicle_sample[grouped_vehicle_sample['REGION'].apply(len) > 1]\n",
    "\n",
    "# Display the result\n",
    "print(multiple_regions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ok I can see both region and pj are have same data values, thus we can use all these to join the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112154, 96)\n"
     ]
    }
   ],
   "source": [
    "# taking accident on left and vehicle on right we can do a left join on ['PSU', 'REGION', 'PJ', 'WEIGHT', 'CASENUM'] these columns \n",
    "\n",
    "# Perform a left join on the specified columns\n",
    "final_merge = pd.merge(merged_data_accident_vehicle, person, on=['WEIGHT', 'PJ', 'CASENUM', 'VEHNO', 'REGION'], how='left')\n",
    "\n",
    "print(final_merge.shape)\n",
    "# Display the result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2332"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "114486-112154"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('PERNO', 159), ('AGE_H', 159), ('SEX_H', 159), ('INJSEV_H', 159), ('PERALC_H', 159), ('PER_TYPE', 159), ('SEAT_POS', 159), ('EJECT', 159), ('SEX', 159), ('HOSPITAL', 159), ('PER_ALCH', 159), ('LOCATN', 159), ('REST_SYS', 159), ('IMPAIRMT', 159), ('ACTION', 159), ('SAF_EQMT', 159), ('AIRBAG', 159)]\n"
     ]
    }
   ],
   "source": [
    "# check for null values\n",
    "t1 = tuple(zip(list(final_merge.columns),list(final_merge.isna().sum())))\n",
    "print([(col, missing) for col, missing in t1 if missing > 0])\n",
    "\n",
    "\n",
    "# There are no null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          CASENUM  HOUR_I  MINUTE_I  RELJCT_I  ALIGN_I  PROFIL_I  SURCON_I  \\\n",
      "1496    110218576      20        35         2        1         1         1   \n",
      "1638    110218850      18        35         1        1         2         1   \n",
      "1890    110219251      17        19         0        1         2         1   \n",
      "2831    110672913       6        23         0        1         1         1   \n",
      "3486    110676327      16         0         0        1         1         1   \n",
      "...           ...     ...       ...       ...      ...       ...       ...   \n",
      "106680  180907055      21         0         3        1         2         2   \n",
      "107453  181111786       5        41         0        1         1         2   \n",
      "108082  182128549      10        20         0        1         1         1   \n",
      "111476  188466213      22         3         0        1         1         1   \n",
      "111748  198143005       6        30         2        1         1         2   \n",
      "\n",
      "        TRFCON_I  LGTCON_I  WEATHR_I  ...  EJECT  SEX  HOSPITAL  PER_ALCH  \\\n",
      "1496           1         3         1  ...    NaN  NaN       NaN       NaN   \n",
      "1638          28         2         1  ...    NaN  NaN       NaN       NaN   \n",
      "1890          28         2         1  ...    NaN  NaN       NaN       NaN   \n",
      "2831           0         4         1  ...    NaN  NaN       NaN       NaN   \n",
      "3486           0         1         1  ...    NaN  NaN       NaN       NaN   \n",
      "...          ...       ...       ...  ...    ...  ...       ...       ...   \n",
      "106680         0         3         1  ...    NaN  NaN       NaN       NaN   \n",
      "107453         0         4         2  ...    NaN  NaN       NaN       NaN   \n",
      "108082         0         1         1  ...    NaN  NaN       NaN       NaN   \n",
      "111476         0         3         1  ...    NaN  NaN       NaN       NaN   \n",
      "111748         0         2         1  ...    NaN  NaN       NaN       NaN   \n",
      "\n",
      "        LOCATN  REST_SYS  IMPAIRMT  ACTION  SAF_EQMT  AIRBAG  \n",
      "1496       NaN       NaN       NaN     NaN       NaN     NaN  \n",
      "1638       NaN       NaN       NaN     NaN       NaN     NaN  \n",
      "1890       NaN       NaN       NaN     NaN       NaN     NaN  \n",
      "2831       NaN       NaN       NaN     NaN       NaN     NaN  \n",
      "3486       NaN       NaN       NaN     NaN       NaN     NaN  \n",
      "...        ...       ...       ...     ...       ...     ...  \n",
      "106680     NaN       NaN       NaN     NaN       NaN     NaN  \n",
      "107453     NaN       NaN       NaN     NaN       NaN     NaN  \n",
      "108082     NaN       NaN       NaN     NaN       NaN     NaN  \n",
      "111476     NaN       NaN       NaN     NaN       NaN     NaN  \n",
      "111748     NaN       NaN       NaN     NaN       NaN     NaN  \n",
      "\n",
      "[159 rows x 96 columns]\n"
     ]
    }
   ],
   "source": [
    "# Filter rows where the 'PERSONID' is NaN (indicating no match)\n",
    "unjoined_rows = final_merge[final_merge['PERNO'].isna()]\n",
    "\n",
    "# Display the unjoined rows\n",
    "print(unjoined_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For these case numbers we actually dont have any information in person column\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([110218576, 110218850, 110219251, 110672913, 110676327, 110756562,\n",
       "       110757472, 113421563, 114920633, 114924743, 115319148, 116657805,\n",
       "       117032669, 117033448, 117033827, 117576518, 117577465, 117579238,\n",
       "       117579326, 117579337, 117581005, 117581941, 117583844, 117588748,\n",
       "       117589168, 118832502, 120410830, 120412365, 120709897, 120851067,\n",
       "       120852123, 120852953, 120854449, 120857183, 120866983, 120872395,\n",
       "       121229052, 121230048, 121230435, 121970681, 121972063, 122274519,\n",
       "       122280189, 122285702, 129926203, 130020558, 130021703, 130226355,\n",
       "       130230035, 130230347, 130237806, 130238759, 130240032, 130244454,\n",
       "       130246639, 130464392, 130599448, 130605297, 130610116, 130610980,\n",
       "       130614259, 130631564, 130632071, 130734063, 131114885, 131246081,\n",
       "       131251250, 131356980, 131357864, 131361884, 131407843, 131408948,\n",
       "       131409110, 131572947, 131582931, 131618271, 131621294, 131720780,\n",
       "       131722196, 131722230, 131724894, 131725683, 131837953, 131844984,\n",
       "       131845201, 131917733, 131918402, 132026422, 132028055, 132029201,\n",
       "       132154699, 132164016, 132164141, 132165106, 132257191, 132257975,\n",
       "       132329994, 132458043, 132547584, 132550201, 132551568, 132681665,\n",
       "       132684410, 132698483, 132710764, 141207356, 147715751, 147718133,\n",
       "       147718717, 147720809, 153509482, 153509547, 153510289, 153513383,\n",
       "       153514938, 159629851, 159639508, 159641537, 160324867, 160330732,\n",
       "       160419555, 160716534, 160817291, 160820330, 161012528, 161805934,\n",
       "       161806592, 162009904, 162711202, 162758788, 162856675, 162857550,\n",
       "       163129541, 163330987, 163710004, 163710164, 164418111, 164513709,\n",
       "       164514898, 164620716, 164620863, 164621144, 164622406, 164917288,\n",
       "       165710496, 165811047, 166257664, 166353503, 180623441, 180907055,\n",
       "       181111786, 182128549, 188466213, 198143005])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get case numbers of unjoined rows\n",
    "\n",
    "print(\"For these case numbers we actually dont have any information in person column\")\n",
    "unjoined_rows[\"CASENUM\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "      WEIGHT  PJ    CASENUM  VEHNO  REGION\n",
      "1509  89.853  10  110218576      2       1\n"
     ]
    }
   ],
   "source": [
    "print(\"person\")\n",
    "print(person[(person.CASENUM == 110218576)][['WEIGHT', 'PJ', 'CASENUM', 'VEHNO', 'REGION']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110218576\n",
      "vehicle\n",
      "      WEIGHT    CASENUM  VEHNO  REGION  PJ\n",
      "1047  89.853  110218576      1       1  10\n",
      "1048  89.853  110218576      2       1  10\n",
      "--------------------------------\n",
      "accident\n",
      "     WEIGHT  PJ    CASENUM  REGION\n",
      "677  89.853  10  110218576       1\n",
      "--------------------------------\n",
      "person\n",
      "      WEIGHT  PJ    CASENUM  VEHNO  REGION\n",
      "1509  89.853  10  110218576      2       1\n",
      "--------------------------------\n",
      "merged_data_accident_vehicle\n",
      "      WEIGHT  PJ    CASENUM  VEHNO  REGION\n",
      "1047  89.853  10  110218576      1       1\n",
      "1048  89.853  10  110218576      2       1\n",
      "--------------------------------\n",
      "final_merge\n",
      "      WEIGHT  PJ    CASENUM  VEHNO  REGION\n",
      "1496  89.853  10  110218576      1       1\n",
      "1497  89.853  10  110218576      2       1\n"
     ]
    }
   ],
   "source": [
    "caseno = 110218576\n",
    "print(caseno)\n",
    "print(\"vehicle\")\n",
    "print(vehicle[(vehicle.CASENUM == caseno)][['WEIGHT', 'CASENUM', 'VEHNO', 'REGION','PJ']])\n",
    "print(\"--------------------------------\")\n",
    "print(\"accident\")\n",
    "print(accident[(accident.CASENUM == caseno)][['WEIGHT', 'PJ', 'CASENUM', 'REGION']])\n",
    "print(\"--------------------------------\")\n",
    "print(\"person\")\n",
    "print(person[(person.CASENUM == caseno)][['WEIGHT', 'PJ', 'CASENUM', 'VEHNO', 'REGION']])\n",
    "print(\"--------------------------------\")\n",
    "print(\"merged_data_accident_vehicle\")\n",
    "print(merged_data_accident_vehicle[(merged_data_accident_vehicle.CASENUM == caseno)][['WEIGHT', 'PJ', 'CASENUM', 'VEHNO', 'REGION']])\n",
    "print(\"--------------------------------\")\n",
    "print(\"final_merge\")\n",
    "print(final_merge[(final_merge.CASENUM == caseno)][['WEIGHT', 'PJ', 'CASENUM', 'VEHNO', 'REGION']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's just remove the null values\n",
    "\n",
    "final_merge_ = final_merge.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CASENUM', 'HOUR_I', 'MINUTE_I', 'RELJCT_I', 'ALIGN_I', 'PROFIL_I',\n",
       "       'SURCON_I', 'TRFCON_I', 'LGTCON_I', 'WEATHR_I', 'MANCOL_I', 'EVENT1_I',\n",
       "       'WEIGHT', 'MONTH', 'WEEKDAY', 'REGION', 'LAND_USE', 'INT_HWY',\n",
       "       'REL_RWY', 'TRAF_WAY', 'ALIGN', 'PROFILE', 'WEATHER', 'SCHL_BUS',\n",
       "       'WRK_ZONE', 'ALCOHOL', 'NUM_LAN', 'HOUR', 'NON_INVL', 'NUM_INJ',\n",
       "       'PED_ACC', 'PJ', 'PSU', 'SPD_LIM', 'VEH_INVL', 'YEAR', 'NO_INJ_I',\n",
       "       'ALCHL_I', 'HAZM_NO', 'MODEL_YR', 'DAM_AREA', 'DR_ZIP_C', 'C_ID_NO',\n",
       "       'HIT_RUN', 'MAKE', 'BODY_TYP', 'SPEC_USE', 'EMCY_USE', 'FACTOR',\n",
       "       'TRAILER', 'JACKNIFE', 'FIRE', 'VEH_SEV', 'TOWED', 'P_CRASH1',\n",
       "       'VEH_ROLE', 'ACC_TYPE', 'IMPACT', 'P_CRASH3', 'PCRASH4', 'PCRASH5',\n",
       "       'ROLLOVER', 'VIOLATN', 'VIS_OBSC', 'DR_DSTRD', 'SPEEDREL', 'V_EVENT',\n",
       "       'VEH_ALCH', 'MAX_VSEV', 'MHENUM', 'NUMOCCS', 'OCC_INVL', 'P_CRASH2',\n",
       "       'SPEED', 'VEHNO', 'IMPACT_H', 'MDLYR_I', 'MXVSEV_I', 'V_ALCH_I',\n",
       "       'PERNO', 'AGE_H', 'SEX_H', 'INJSEV_H', 'PERALC_H', 'PER_TYPE',\n",
       "       'SEAT_POS', 'EJECT', 'SEX', 'HOSPITAL', 'PER_ALCH', 'LOCATN',\n",
       "       'REST_SYS', 'IMPAIRMT', 'ACTION', 'SAF_EQMT', 'AIRBAG'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_merge_.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50967, 96)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Dictionary with column names as keys and values to be removed\n",
    "remove_values = {\n",
    "    'LGTCON_I': 8, 'WEATHR_I': 9, 'MANCOL_I': 9, 'WEEKDAY': 9, 'LAND_USE': 9, \n",
    "    'MAN_COL': 9, 'INT_HWY': 9, 'REL_JCT': 98, 'REL_RWY': 98, 'ALIGN': 9, \n",
    "    'PROFILE': 9, 'SUR_COND': 9, 'TRAF_CON': 9, 'LGHT_CON': 8, 'WEATHER': 9, \n",
    "    'ALCOHOL': 9, 'NUM_LAN': 9, 'EVENT1': 99, 'HOUR': 99, 'MINUTE': 99, \n",
    "    'NUM_INJ': 99, 'VEHNO': 99, 'INJSEV_H': 99, 'SEAT_H': 8, 'PER_TYPE': 99, \n",
    "    'SEAT_POS': 3, 'EJECT': 9, 'SEX': 9, 'HOSPITAL': 9, 'PER_ALCH': 99, \n",
    "    'LOCATN': 9, 'REST_SYS': 9, 'PER_DRUG': 99, 'IMPAIRMT': 99, 'ACTION': 9, \n",
    "    'SAF_EQMT': 9, 'REGION': 99, 'STR_VEH': 3, 'VIN': 999, 'HAZM_NO': 999, \n",
    "    'DAM_AREA': 9, 'HIT_RUN': 9, 'SPEC_USE': 99, 'EMCY_USE': 9, 'FACTOR': 99, \n",
    "    'TRAILER': 6, 'VEH_SEV': 9, 'TOWED': 9, 'P_CRASH1': 99, 'VEH_ROLE': 9, \n",
    "    'P_CRASH3': 99, 'PCRASH5': 99, 'CARG_TYP': 99, 'DR_PRES': 9, 'VIOLATN': 96, \n",
    "    'VIS_OBSC': 96, 'DRMAN_AV': 96, 'DR_DSTRD': 96, 'SPEEDREL': 9, 'VEH_ALCH': 9, \n",
    "    'MAX_VSEV': 9, 'NUMOCCS': 999, 'OCC_INVL': 97, 'SPEED': 999, 'VROLE_I': 9, \n",
    "    'V_EVNT_H': 99\n",
    "}\n",
    "\n",
    "# Loop over the dictionary to filter rows based on column names and values\n",
    "for column, value in remove_values.items():\n",
    "    if column in final_merge_.columns:\n",
    "        final_merge_cleaned = final_merge_[final_merge_[column] != value]\n",
    "\n",
    "# The filtered dataframe is now in final_merge\n",
    "final_merge_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merge_cleaned.to_csv(\"cleaned_data/final_merge_cleaned.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 50967 entries, 5 to 112153\n",
      "Data columns (total 96 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   CASENUM   50967 non-null  int64  \n",
      " 1   HOUR_I    50967 non-null  int64  \n",
      " 2   MINUTE_I  50967 non-null  int64  \n",
      " 3   RELJCT_I  50967 non-null  int64  \n",
      " 4   ALIGN_I   50967 non-null  int64  \n",
      " 5   PROFIL_I  50967 non-null  int64  \n",
      " 6   SURCON_I  50967 non-null  int64  \n",
      " 7   TRFCON_I  50967 non-null  int64  \n",
      " 8   LGTCON_I  50967 non-null  int64  \n",
      " 9   WEATHR_I  50967 non-null  int64  \n",
      " 10  MANCOL_I  50967 non-null  int64  \n",
      " 11  EVENT1_I  50967 non-null  int64  \n",
      " 12  WEIGHT    50967 non-null  float64\n",
      " 13  MONTH     50967 non-null  int64  \n",
      " 14  WEEKDAY   50967 non-null  int64  \n",
      " 15  REGION    50967 non-null  int64  \n",
      " 16  LAND_USE  50967 non-null  int64  \n",
      " 17  INT_HWY   50967 non-null  int64  \n",
      " 18  REL_RWY   50967 non-null  int64  \n",
      " 19  TRAF_WAY  50967 non-null  int64  \n",
      " 20  ALIGN     50967 non-null  int64  \n",
      " 21  PROFILE   50967 non-null  int64  \n",
      " 22  WEATHER   50967 non-null  int64  \n",
      " 23  SCHL_BUS  50967 non-null  int64  \n",
      " 24  WRK_ZONE  50967 non-null  int64  \n",
      " 25  ALCOHOL   50967 non-null  int64  \n",
      " 26  NUM_LAN   50967 non-null  int64  \n",
      " 27  HOUR      50967 non-null  int64  \n",
      " 28  NON_INVL  50967 non-null  int64  \n",
      " 29  NUM_INJ   50967 non-null  int64  \n",
      " 30  PED_ACC   50967 non-null  int64  \n",
      " 31  PJ        50967 non-null  int64  \n",
      " 32  PSU       50967 non-null  int64  \n",
      " 33  SPD_LIM   50967 non-null  int64  \n",
      " 34  VEH_INVL  50967 non-null  int64  \n",
      " 35  YEAR      50967 non-null  int64  \n",
      " 36  NO_INJ_I  50967 non-null  int64  \n",
      " 37  ALCHL_I   50967 non-null  int64  \n",
      " 38  HAZM_NO   50967 non-null  int64  \n",
      " 39  MODEL_YR  50967 non-null  int64  \n",
      " 40  DAM_AREA  50967 non-null  int64  \n",
      " 41  DR_ZIP_C  50967 non-null  int64  \n",
      " 42  C_ID_NO   50967 non-null  int64  \n",
      " 43  HIT_RUN   50967 non-null  int64  \n",
      " 44  MAKE      50967 non-null  int64  \n",
      " 45  BODY_TYP  50967 non-null  int64  \n",
      " 46  SPEC_USE  50967 non-null  int64  \n",
      " 47  EMCY_USE  50967 non-null  int64  \n",
      " 48  FACTOR    50967 non-null  int64  \n",
      " 49  TRAILER   50967 non-null  int64  \n",
      " 50  JACKNIFE  50967 non-null  int64  \n",
      " 51  FIRE      50967 non-null  int64  \n",
      " 52  VEH_SEV   50967 non-null  int64  \n",
      " 53  TOWED     50967 non-null  int64  \n",
      " 54  P_CRASH1  50967 non-null  int64  \n",
      " 55  VEH_ROLE  50967 non-null  int64  \n",
      " 56  ACC_TYPE  50967 non-null  int64  \n",
      " 57  IMPACT    50967 non-null  int64  \n",
      " 58  P_CRASH3  50967 non-null  int64  \n",
      " 59  PCRASH4   50967 non-null  int64  \n",
      " 60  PCRASH5   50967 non-null  int64  \n",
      " 61  ROLLOVER  50967 non-null  int64  \n",
      " 62  VIOLATN   50967 non-null  int64  \n",
      " 63  VIS_OBSC  50967 non-null  int64  \n",
      " 64  DR_DSTRD  50967 non-null  int64  \n",
      " 65  SPEEDREL  50967 non-null  int64  \n",
      " 66  V_EVENT   50967 non-null  int64  \n",
      " 67  VEH_ALCH  50967 non-null  int64  \n",
      " 68  MAX_VSEV  50967 non-null  int64  \n",
      " 69  MHENUM    50967 non-null  int64  \n",
      " 70  NUMOCCS   50967 non-null  int64  \n",
      " 71  OCC_INVL  50967 non-null  int64  \n",
      " 72  P_CRASH2  50967 non-null  int64  \n",
      " 73  SPEED     50967 non-null  int64  \n",
      " 74  VEHNO     50967 non-null  int64  \n",
      " 75  IMPACT_H  50967 non-null  int64  \n",
      " 76  MDLYR_I   50967 non-null  int64  \n",
      " 77  MXVSEV_I  50967 non-null  int64  \n",
      " 78  V_ALCH_I  50967 non-null  int64  \n",
      " 79  PERNO     50967 non-null  float64\n",
      " 80  AGE_H     50967 non-null  float64\n",
      " 81  SEX_H     50967 non-null  float64\n",
      " 82  INJSEV_H  50967 non-null  float64\n",
      " 83  PERALC_H  50967 non-null  float64\n",
      " 84  PER_TYPE  50967 non-null  float64\n",
      " 85  SEAT_POS  50967 non-null  float64\n",
      " 86  EJECT     50967 non-null  float64\n",
      " 87  SEX       50967 non-null  float64\n",
      " 88  HOSPITAL  50967 non-null  float64\n",
      " 89  PER_ALCH  50967 non-null  float64\n",
      " 90  LOCATN    50967 non-null  float64\n",
      " 91  REST_SYS  50967 non-null  float64\n",
      " 92  IMPAIRMT  50967 non-null  float64\n",
      " 93  ACTION    50967 non-null  float64\n",
      " 94  SAF_EQMT  50967 non-null  float64\n",
      " 95  AIRBAG    50967 non-null  float64\n",
      "dtypes: float64(18), int64(78)\n",
      "memory usage: 37.7 MB\n"
     ]
    }
   ],
   "source": [
    "final_merge_cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting FLAML\n",
      "  Using cached FLAML-2.3.4-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: NumPy>=1.17 in /opt/anaconda3/lib/python3.12/site-packages (from FLAML) (1.26.4)\n",
      "Using cached FLAML-2.3.4-py3-none-any.whl (314 kB)\n",
      "Installing collected packages: FLAML\n",
      "Successfully installed FLAML-2.3.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install FLAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in /opt/anaconda3/lib/python3.12/site-packages (1.2.7)\n",
      "Requirement already satisfied: graphviz in /opt/anaconda3/lib/python3.12/site-packages (from catboost) (0.20.3)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/lib/python3.12/site-packages (from catboost) (3.9.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /opt/anaconda3/lib/python3.12/site-packages (from catboost) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.24 in /opt/anaconda3/lib/python3.12/site-packages (from catboost) (2.2.2)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.12/site-packages (from catboost) (1.13.1)\n",
      "Requirement already satisfied: plotly in /opt/anaconda3/lib/python3.12/site-packages (from catboost) (5.24.1)\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.12/site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=0.24->catboost) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=0.24->catboost) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->catboost) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->catboost) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->catboost) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->catboost) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->catboost) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->catboost) (3.1.2)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from plotly->catboost) (8.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: datasets in /opt/anaconda3/lib/python3.12/site-packages (3.2.0)\n",
      "Collecting datasets\n",
      "  Downloading datasets-3.4.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (4.66.5)\n",
      "Requirement already satisfied: xxhash in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (3.10.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (0.27.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (25.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.11.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Downloading datasets-3.4.1-py3-none-any.whl (487 kB)\n",
      "Installing collected packages: datasets\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 3.2.0\n",
      "    Uninstalling datasets-3.2.0:\n",
      "      Successfully uninstalled datasets-3.2.0\n",
      "Successfully installed datasets-3.4.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install catboost\n",
    "%pip install --upgrade datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X,y = final_merge_cleaned.drop(['CASENUM','INJSEV_H'],axis=1),final_merge_cleaned[['INJSEV_H']]\n",
    "X= np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from flaml import AutoML\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40773, 94), (10194, 94), (40773, 1), (10194, 1))"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 03-23 15:36:37] {1728} INFO - task = classification\n",
      "[flaml.automl.logger: 03-23 15:36:37] {1739} INFO - Evaluation method: holdout\n",
      "[flaml.automl.logger: 03-23 15:36:37] {1838} INFO - Minimizing error metric: 1-accuracy\n",
      "[flaml.automl.logger: 03-23 15:36:37] {1955} INFO - List of ML learners in AutoML Run: ['xgboost', 'rf', 'extra_tree', 'xgb_limitdepth', 'sgd', 'catboost', 'lrl1']\n",
      "[flaml.automl.logger: 03-23 15:36:37] {2258} INFO - iteration 0, current learner xgboost\n",
      "[flaml.automl.logger: 03-23 15:36:37] {2393} INFO - Estimated sufficient time budget=986s. Estimated necessary time budget=15s.\n",
      "[flaml.automl.logger: 03-23 15:36:37] {2442} INFO -  at 0.2s,\testimator xgboost's best error=0.0649,\tbest estimator xgboost's best error=0.0649\n",
      "[flaml.automl.logger: 03-23 15:36:37] {2258} INFO - iteration 1, current learner sgd\n",
      "[flaml.automl.logger: 03-23 15:36:38] {2442} INFO -  at 0.4s,\testimator sgd's best error=0.2871,\tbest estimator xgboost's best error=0.0649\n",
      "[flaml.automl.logger: 03-23 15:36:38] {2258} INFO - iteration 2, current learner xgboost\n",
      "[flaml.automl.logger: 03-23 15:36:38] {2442} INFO -  at 0.7s,\testimator xgboost's best error=0.0649,\tbest estimator xgboost's best error=0.0649\n",
      "[flaml.automl.logger: 03-23 15:36:38] {2258} INFO - iteration 3, current learner extra_tree\n",
      "[flaml.automl.logger: 03-23 15:36:38] {2442} INFO -  at 0.7s,\testimator extra_tree's best error=0.2812,\tbest estimator xgboost's best error=0.0649\n",
      "[flaml.automl.logger: 03-23 15:36:38] {2258} INFO - iteration 4, current learner extra_tree\n",
      "[flaml.automl.logger: 03-23 15:36:38] {2442} INFO -  at 0.8s,\testimator extra_tree's best error=0.1894,\tbest estimator xgboost's best error=0.0649\n",
      "[flaml.automl.logger: 03-23 15:36:38] {2258} INFO - iteration 5, current learner rf\n",
      "[flaml.automl.logger: 03-23 15:36:38] {2442} INFO -  at 0.9s,\testimator rf's best error=0.2119,\tbest estimator xgboost's best error=0.0649\n",
      "[flaml.automl.logger: 03-23 15:36:38] {2258} INFO - iteration 6, current learner xgboost\n",
      "[flaml.automl.logger: 03-23 15:36:38] {2442} INFO -  at 1.0s,\testimator xgboost's best error=0.0649,\tbest estimator xgboost's best error=0.0649\n",
      "[flaml.automl.logger: 03-23 15:36:38] {2258} INFO - iteration 7, current learner rf\n",
      "[flaml.automl.logger: 03-23 15:36:38] {2442} INFO -  at 1.0s,\testimator rf's best error=0.1185,\tbest estimator xgboost's best error=0.0649\n",
      "[flaml.automl.logger: 03-23 15:36:38] {2258} INFO - iteration 8, current learner rf\n",
      "[flaml.automl.logger: 03-23 15:36:38] {2442} INFO -  at 1.1s,\testimator rf's best error=0.1185,\tbest estimator xgboost's best error=0.0649\n",
      "[flaml.automl.logger: 03-23 15:36:38] {2258} INFO - iteration 9, current learner xgboost\n",
      "[flaml.automl.logger: 03-23 15:36:38] {2442} INFO -  at 1.2s,\testimator xgboost's best error=0.0631,\tbest estimator xgboost's best error=0.0631\n",
      "[flaml.automl.logger: 03-23 15:36:38] {2258} INFO - iteration 10, current learner rf\n",
      "[flaml.automl.logger: 03-23 15:36:38] {2442} INFO -  at 1.3s,\testimator rf's best error=0.1185,\tbest estimator xgboost's best error=0.0631\n",
      "[flaml.automl.logger: 03-23 15:36:38] {2258} INFO - iteration 11, current learner rf\n",
      "[flaml.automl.logger: 03-23 15:36:38] {2442} INFO -  at 1.4s,\testimator rf's best error=0.0793,\tbest estimator xgboost's best error=0.0631\n",
      "[flaml.automl.logger: 03-23 15:36:38] {2258} INFO - iteration 12, current learner rf\n",
      "[flaml.automl.logger: 03-23 15:36:39] {2442} INFO -  at 1.5s,\testimator rf's best error=0.0793,\tbest estimator xgboost's best error=0.0631\n",
      "[flaml.automl.logger: 03-23 15:36:39] {2258} INFO - iteration 13, current learner extra_tree\n",
      "[flaml.automl.logger: 03-23 15:36:39] {2442} INFO -  at 1.6s,\testimator extra_tree's best error=0.1894,\tbest estimator xgboost's best error=0.0631\n",
      "[flaml.automl.logger: 03-23 15:36:39] {2258} INFO - iteration 14, current learner rf\n",
      "[flaml.automl.logger: 03-23 15:36:39] {2442} INFO -  at 1.7s,\testimator rf's best error=0.0715,\tbest estimator xgboost's best error=0.0631\n",
      "[flaml.automl.logger: 03-23 15:36:39] {2258} INFO - iteration 15, current learner sgd\n",
      "[flaml.automl.logger: 03-23 15:36:39] {2442} INFO -  at 1.9s,\testimator sgd's best error=0.2871,\tbest estimator xgboost's best error=0.0631\n",
      "[flaml.automl.logger: 03-23 15:36:39] {2258} INFO - iteration 16, current learner xgboost\n",
      "[flaml.automl.logger: 03-23 15:36:39] {2442} INFO -  at 2.2s,\testimator xgboost's best error=0.0502,\tbest estimator xgboost's best error=0.0502\n",
      "[flaml.automl.logger: 03-23 15:36:39] {2258} INFO - iteration 17, current learner sgd\n",
      "[flaml.automl.logger: 03-23 15:36:40] {2442} INFO -  at 2.5s,\testimator sgd's best error=0.2871,\tbest estimator xgboost's best error=0.0502\n",
      "[flaml.automl.logger: 03-23 15:36:40] {2258} INFO - iteration 18, current learner xgboost\n",
      "[flaml.automl.logger: 03-23 15:36:40] {2442} INFO -  at 2.8s,\testimator xgboost's best error=0.0502,\tbest estimator xgboost's best error=0.0502\n",
      "[flaml.automl.logger: 03-23 15:36:40] {2258} INFO - iteration 19, current learner extra_tree\n",
      "[flaml.automl.logger: 03-23 15:36:40] {2442} INFO -  at 2.9s,\testimator extra_tree's best error=0.1894,\tbest estimator xgboost's best error=0.0502\n",
      "[flaml.automl.logger: 03-23 15:36:40] {2258} INFO - iteration 20, current learner xgboost\n",
      "[flaml.automl.logger: 03-23 15:36:40] {2442} INFO -  at 3.0s,\testimator xgboost's best error=0.0494,\tbest estimator xgboost's best error=0.0494\n",
      "[flaml.automl.logger: 03-23 15:36:40] {2258} INFO - iteration 21, current learner rf\n",
      "[flaml.automl.logger: 03-23 15:36:40] {2442} INFO -  at 3.2s,\testimator rf's best error=0.0715,\tbest estimator xgboost's best error=0.0494\n",
      "[flaml.automl.logger: 03-23 15:36:40] {2258} INFO - iteration 22, current learner xgboost\n",
      "[flaml.automl.logger: 03-23 15:36:41] {2442} INFO -  at 3.5s,\testimator xgboost's best error=0.0470,\tbest estimator xgboost's best error=0.0470\n",
      "[flaml.automl.logger: 03-23 15:36:41] {2258} INFO - iteration 23, current learner xgboost\n",
      "[flaml.automl.logger: 03-23 15:36:41] {2442} INFO -  at 3.6s,\testimator xgboost's best error=0.0470,\tbest estimator xgboost's best error=0.0470\n",
      "[flaml.automl.logger: 03-23 15:36:41] {2258} INFO - iteration 24, current learner extra_tree\n",
      "[flaml.automl.logger: 03-23 15:36:41] {2442} INFO -  at 3.7s,\testimator extra_tree's best error=0.0874,\tbest estimator xgboost's best error=0.0470\n",
      "[flaml.automl.logger: 03-23 15:36:41] {2258} INFO - iteration 25, current learner sgd\n",
      "[flaml.automl.logger: 03-23 15:36:43] {2442} INFO -  at 5.9s,\testimator sgd's best error=0.2871,\tbest estimator xgboost's best error=0.0470\n",
      "[flaml.automl.logger: 03-23 15:36:43] {2258} INFO - iteration 26, current learner xgboost\n",
      "[flaml.automl.logger: 03-23 15:36:44] {2442} INFO -  at 6.4s,\testimator xgboost's best error=0.0470,\tbest estimator xgboost's best error=0.0470\n",
      "[flaml.automl.logger: 03-23 15:36:44] {2258} INFO - iteration 27, current learner extra_tree\n",
      "[flaml.automl.logger: 03-23 15:36:44] {2442} INFO -  at 6.5s,\testimator extra_tree's best error=0.0874,\tbest estimator xgboost's best error=0.0470\n",
      "[flaml.automl.logger: 03-23 15:36:44] {2258} INFO - iteration 28, current learner extra_tree\n",
      "[flaml.automl.logger: 03-23 15:36:44] {2442} INFO -  at 6.6s,\testimator extra_tree's best error=0.0820,\tbest estimator xgboost's best error=0.0470\n",
      "[flaml.automl.logger: 03-23 15:36:44] {2258} INFO - iteration 29, current learner extra_tree\n",
      "[flaml.automl.logger: 03-23 15:36:44] {2442} INFO -  at 6.7s,\testimator extra_tree's best error=0.0820,\tbest estimator xgboost's best error=0.0470\n",
      "[flaml.automl.logger: 03-23 15:36:44] {2258} INFO - iteration 30, current learner xgboost\n",
      "[flaml.automl.logger: 03-23 15:36:44] {2442} INFO -  at 7.0s,\testimator xgboost's best error=0.0470,\tbest estimator xgboost's best error=0.0470\n",
      "[flaml.automl.logger: 03-23 15:36:44] {2258} INFO - iteration 31, current learner catboost\n",
      "[flaml.automl.logger: 03-23 15:36:48] {2442} INFO -  at 11.1s,\testimator catboost's best error=0.0453,\tbest estimator catboost's best error=0.0453\n",
      "[flaml.automl.logger: 03-23 15:36:48] {2258} INFO - iteration 32, current learner xgboost\n",
      "[flaml.automl.logger: 03-23 15:36:48] {2442} INFO -  at 11.3s,\testimator xgboost's best error=0.0470,\tbest estimator catboost's best error=0.0453\n",
      "[flaml.automl.logger: 03-23 15:36:48] {2258} INFO - iteration 33, current learner xgboost\n",
      "[flaml.automl.logger: 03-23 15:36:49] {2442} INFO -  at 11.8s,\testimator xgboost's best error=0.0470,\tbest estimator catboost's best error=0.0453\n",
      "[flaml.automl.logger: 03-23 15:36:49] {2258} INFO - iteration 34, current learner catboost\n",
      "[flaml.automl.logger: 03-23 15:36:54] {2442} INFO -  at 17.1s,\testimator catboost's best error=0.0453,\tbest estimator catboost's best error=0.0453\n",
      "[flaml.automl.logger: 03-23 15:36:54] {2258} INFO - iteration 35, current learner xgboost\n",
      "[flaml.automl.logger: 03-23 15:36:54] {2442} INFO -  at 17.2s,\testimator xgboost's best error=0.0470,\tbest estimator catboost's best error=0.0453\n",
      "[flaml.automl.logger: 03-23 15:36:54] {2258} INFO - iteration 36, current learner rf\n",
      "[flaml.automl.logger: 03-23 15:36:54] {2442} INFO -  at 17.3s,\testimator rf's best error=0.0715,\tbest estimator catboost's best error=0.0453\n",
      "[flaml.automl.logger: 03-23 15:36:54] {2258} INFO - iteration 37, current learner catboost\n",
      "[flaml.automl.logger: 03-23 15:36:58] {2442} INFO -  at 21.3s,\testimator catboost's best error=0.0453,\tbest estimator catboost's best error=0.0453\n",
      "[flaml.automl.logger: 03-23 15:36:58] {2258} INFO - iteration 38, current learner rf\n",
      "[flaml.automl.logger: 03-23 15:36:59] {2442} INFO -  at 21.4s,\testimator rf's best error=0.0715,\tbest estimator catboost's best error=0.0453\n",
      "[flaml.automl.logger: 03-23 15:36:59] {2258} INFO - iteration 39, current learner extra_tree\n",
      "[flaml.automl.logger: 03-23 15:36:59] {2442} INFO -  at 21.5s,\testimator extra_tree's best error=0.0820,\tbest estimator catboost's best error=0.0453\n",
      "[flaml.automl.logger: 03-23 15:36:59] {2258} INFO - iteration 40, current learner rf\n",
      "[flaml.automl.logger: 03-23 15:36:59] {2442} INFO -  at 21.6s,\testimator rf's best error=0.0627,\tbest estimator catboost's best error=0.0453\n",
      "[flaml.automl.logger: 03-23 15:36:59] {2258} INFO - iteration 41, current learner extra_tree\n",
      "[flaml.automl.logger: 03-23 15:36:59] {2442} INFO -  at 21.7s,\testimator extra_tree's best error=0.0820,\tbest estimator catboost's best error=0.0453\n",
      "[flaml.automl.logger: 03-23 15:36:59] {2258} INFO - iteration 42, current learner sgd\n",
      "[flaml.automl.logger: 03-23 15:36:59] {2442} INFO -  at 21.8s,\testimator sgd's best error=0.2871,\tbest estimator catboost's best error=0.0453\n",
      "[flaml.automl.logger: 03-23 15:36:59] {2258} INFO - iteration 43, current learner xgboost\n",
      "[flaml.automl.logger: 03-23 15:37:00] {2442} INFO -  at 22.7s,\testimator xgboost's best error=0.0470,\tbest estimator catboost's best error=0.0453\n",
      "[flaml.automl.logger: 03-23 15:37:00] {2258} INFO - iteration 44, current learner extra_tree\n",
      "[flaml.automl.logger: 03-23 15:37:00] {2442} INFO -  at 22.8s,\testimator extra_tree's best error=0.0820,\tbest estimator catboost's best error=0.0453\n",
      "[flaml.automl.logger: 03-23 15:37:00] {2258} INFO - iteration 45, current learner catboost\n",
      "[flaml.automl.logger: 03-23 15:37:05] {2442} INFO -  at 27.8s,\testimator catboost's best error=0.0453,\tbest estimator catboost's best error=0.0453\n",
      "[flaml.automl.logger: 03-23 15:37:05] {2258} INFO - iteration 46, current learner extra_tree\n",
      "[flaml.automl.logger: 03-23 15:37:05] {2442} INFO -  at 27.9s,\testimator extra_tree's best error=0.0820,\tbest estimator catboost's best error=0.0453\n",
      "[flaml.automl.logger: 03-23 15:37:05] {2258} INFO - iteration 47, current learner rf\n",
      "[flaml.automl.logger: 03-23 15:37:05] {2442} INFO -  at 27.9s,\testimator rf's best error=0.0627,\tbest estimator catboost's best error=0.0453\n",
      "[flaml.automl.logger: 03-23 15:37:05] {2258} INFO - iteration 48, current learner sgd\n",
      "[flaml.automl.logger: 03-23 15:37:07] {2442} INFO -  at 30.3s,\testimator sgd's best error=0.2871,\tbest estimator catboost's best error=0.0453\n",
      "[flaml.automl.logger: 03-23 15:37:07] {2258} INFO - iteration 49, current learner xgboost\n",
      "[flaml.automl.logger: 03-23 15:37:08] {2442} INFO -  at 30.6s,\testimator xgboost's best error=0.0470,\tbest estimator catboost's best error=0.0453\n",
      "[flaml.automl.logger: 03-23 15:37:08] {2258} INFO - iteration 50, current learner rf\n",
      "[flaml.automl.logger: 03-23 15:37:08] {2442} INFO -  at 30.8s,\testimator rf's best error=0.0556,\tbest estimator catboost's best error=0.0453\n",
      "[flaml.automl.logger: 03-23 15:37:08] {2258} INFO - iteration 51, current learner extra_tree\n",
      "[flaml.automl.logger: 03-23 15:37:08] {2442} INFO -  at 30.9s,\testimator extra_tree's best error=0.0820,\tbest estimator catboost's best error=0.0453\n",
      "[flaml.automl.logger: 03-23 15:37:08] {2258} INFO - iteration 52, current learner rf\n",
      "[flaml.automl.logger: 03-23 15:37:08] {2442} INFO -  at 31.0s,\testimator rf's best error=0.0502,\tbest estimator catboost's best error=0.0453\n",
      "[flaml.automl.logger: 03-23 15:37:08] {2258} INFO - iteration 53, current learner rf\n",
      "[flaml.automl.logger: 03-23 15:37:08] {2442} INFO -  at 31.2s,\testimator rf's best error=0.0502,\tbest estimator catboost's best error=0.0453\n",
      "[flaml.automl.logger: 03-23 15:37:08] {2258} INFO - iteration 54, current learner rf\n",
      "[flaml.automl.logger: 03-23 15:37:08] {2442} INFO -  at 31.3s,\testimator rf's best error=0.0502,\tbest estimator catboost's best error=0.0453\n",
      "[flaml.automl.logger: 03-23 15:37:08] {2258} INFO - iteration 55, current learner xgboost\n",
      "[flaml.automl.logger: 03-23 15:37:09] {2442} INFO -  at 31.9s,\testimator xgboost's best error=0.0470,\tbest estimator catboost's best error=0.0453\n",
      "[flaml.automl.logger: 03-23 15:37:09] {2258} INFO - iteration 56, current learner rf\n",
      "[flaml.automl.logger: 03-23 15:37:09] {2442} INFO -  at 32.0s,\testimator rf's best error=0.0502,\tbest estimator catboost's best error=0.0453\n",
      "[flaml.automl.logger: 03-23 15:37:09] {2258} INFO - iteration 57, current learner rf\n",
      "[flaml.automl.logger: 03-23 15:37:09] {2442} INFO -  at 32.1s,\testimator rf's best error=0.0502,\tbest estimator catboost's best error=0.0453\n",
      "[flaml.automl.logger: 03-23 15:37:09] {2258} INFO - iteration 58, current learner rf\n",
      "[flaml.automl.logger: 03-23 15:37:09] {2442} INFO -  at 32.3s,\testimator rf's best error=0.0499,\tbest estimator catboost's best error=0.0453\n",
      "[flaml.automl.logger: 03-23 15:37:09] {2258} INFO - iteration 59, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 03-23 15:37:10] {2442} INFO -  at 32.4s,\testimator xgb_limitdepth's best error=0.0482,\tbest estimator catboost's best error=0.0453\n",
      "[flaml.automl.logger: 03-23 15:37:10] {2258} INFO - iteration 60, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 03-23 15:37:10] {2442} INFO -  at 32.6s,\testimator xgb_limitdepth's best error=0.0482,\tbest estimator catboost's best error=0.0453\n",
      "[flaml.automl.logger: 03-23 15:37:10] {2258} INFO - iteration 61, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 03-23 15:37:10] {2442} INFO -  at 32.8s,\testimator xgb_limitdepth's best error=0.0482,\tbest estimator catboost's best error=0.0453\n",
      "[flaml.automl.logger: 03-23 15:37:10] {2258} INFO - iteration 62, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 03-23 15:37:10] {2442} INFO -  at 32.9s,\testimator xgb_limitdepth's best error=0.0477,\tbest estimator catboost's best error=0.0453\n",
      "[flaml.automl.logger: 03-23 15:37:10] {2258} INFO - iteration 63, current learner xgboost\n",
      "[flaml.automl.logger: 03-23 15:37:10] {2442} INFO -  at 33.1s,\testimator xgboost's best error=0.0470,\tbest estimator catboost's best error=0.0453\n",
      "[flaml.automl.logger: 03-23 15:37:10] {2258} INFO - iteration 64, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 03-23 15:37:10] {2442} INFO -  at 33.2s,\testimator xgb_limitdepth's best error=0.0470,\tbest estimator catboost's best error=0.0453\n",
      "[flaml.automl.logger: 03-23 15:37:10] {2258} INFO - iteration 65, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 03-23 15:37:10] {2442} INFO -  at 33.3s,\testimator xgb_limitdepth's best error=0.0470,\tbest estimator catboost's best error=0.0453\n",
      "[flaml.automl.logger: 03-23 15:37:10] {2258} INFO - iteration 66, current learner xgboost\n",
      "[flaml.automl.logger: 03-23 15:37:11] {2442} INFO -  at 34.0s,\testimator xgboost's best error=0.0453,\tbest estimator catboost's best error=0.0453\n",
      "[flaml.automl.logger: 03-23 15:37:11] {2258} INFO - iteration 67, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 03-23 15:37:12] {2442} INFO -  at 34.4s,\testimator xgb_limitdepth's best error=0.0470,\tbest estimator catboost's best error=0.0453\n",
      "[flaml.automl.logger: 03-23 15:37:12] {2258} INFO - iteration 68, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 03-23 15:37:12] {2442} INFO -  at 34.8s,\testimator xgb_limitdepth's best error=0.0470,\tbest estimator catboost's best error=0.0453\n",
      "[flaml.automl.logger: 03-23 15:37:12] {2258} INFO - iteration 69, current learner extra_tree\n",
      "[flaml.automl.logger: 03-23 15:37:12] {2442} INFO -  at 34.9s,\testimator extra_tree's best error=0.0820,\tbest estimator catboost's best error=0.0453\n",
      "[flaml.automl.logger: 03-23 15:37:12] {2258} INFO - iteration 70, current learner xgboost\n",
      "[flaml.automl.logger: 03-23 15:37:12] {2442} INFO -  at 35.2s,\testimator xgboost's best error=0.0453,\tbest estimator catboost's best error=0.0453\n",
      "[flaml.automl.logger: 03-23 15:37:12] {2258} INFO - iteration 71, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 03-23 15:37:12] {2442} INFO -  at 35.3s,\testimator xgb_limitdepth's best error=0.0470,\tbest estimator catboost's best error=0.0453\n",
      "[flaml.automl.logger: 03-23 15:37:12] {2258} INFO - iteration 72, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 03-23 15:37:13] {2442} INFO -  at 35.4s,\testimator xgb_limitdepth's best error=0.0470,\tbest estimator catboost's best error=0.0453\n",
      "[flaml.automl.logger: 03-23 15:37:13] {2258} INFO - iteration 73, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 03-23 15:37:13] {2442} INFO -  at 35.6s,\testimator xgb_limitdepth's best error=0.0470,\tbest estimator catboost's best error=0.0453\n",
      "[flaml.automl.logger: 03-23 15:37:13] {2258} INFO - iteration 74, current learner catboost\n",
      "[flaml.automl.logger: 03-23 15:37:16] {2442} INFO -  at 38.8s,\testimator catboost's best error=0.0453,\tbest estimator catboost's best error=0.0453\n",
      "[flaml.automl.logger: 03-23 15:37:16] {2258} INFO - iteration 75, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 03-23 15:37:16] {2442} INFO -  at 38.9s,\testimator xgb_limitdepth's best error=0.0470,\tbest estimator catboost's best error=0.0453\n",
      "[flaml.automl.logger: 03-23 15:37:16] {2258} INFO - iteration 76, current learner sgd\n",
      "[flaml.automl.logger: 03-23 15:37:16] {2442} INFO -  at 39.0s,\testimator sgd's best error=0.2871,\tbest estimator catboost's best error=0.0453\n",
      "[flaml.automl.logger: 03-23 15:37:16] {2258} INFO - iteration 77, current learner xgboost\n",
      "[flaml.automl.logger: 03-23 15:37:19] {2442} INFO -  at 42.1s,\testimator xgboost's best error=0.0453,\tbest estimator catboost's best error=0.0453\n",
      "[flaml.automl.logger: 03-23 15:37:19] {2258} INFO - iteration 78, current learner xgboost\n",
      "[flaml.automl.logger: 03-23 15:37:20] {2442} INFO -  at 42.7s,\testimator xgboost's best error=0.0448,\tbest estimator xgboost's best error=0.0448\n",
      "[flaml.automl.logger: 03-23 15:37:20] {2258} INFO - iteration 79, current learner sgd\n",
      "[flaml.automl.logger: 03-23 15:37:20] {2442} INFO -  at 42.8s,\testimator sgd's best error=0.2871,\tbest estimator xgboost's best error=0.0448\n",
      "[flaml.automl.logger: 03-23 15:37:20] {2258} INFO - iteration 80, current learner rf\n",
      "[flaml.automl.logger: 03-23 15:37:20] {2442} INFO -  at 43.2s,\testimator rf's best error=0.0499,\tbest estimator xgboost's best error=0.0448\n",
      "[flaml.automl.logger: 03-23 15:37:20] {2258} INFO - iteration 81, current learner xgboost\n",
      "[flaml.automl.logger: 03-23 15:37:21] {2442} INFO -  at 43.8s,\testimator xgboost's best error=0.0448,\tbest estimator xgboost's best error=0.0448\n",
      "[flaml.automl.logger: 03-23 15:37:21] {2258} INFO - iteration 82, current learner catboost\n",
      "[flaml.automl.logger: 03-23 15:37:56] {2442} INFO -  at 78.4s,\testimator catboost's best error=0.0453,\tbest estimator xgboost's best error=0.0448\n",
      "[flaml.automl.logger: 03-23 15:37:56] {2685} INFO - retrain xgboost for 0.6s\n",
      "[flaml.automl.logger: 03-23 15:37:56] {2688} INFO - retrained model: XGBClassifier(base_score=None, booster=None, callbacks=[],\n",
      "              colsample_bylevel=0.7563793731764131, colsample_bynode=None,\n",
      "              colsample_bytree=0.7647693832410042, device=None,\n",
      "              early_stopping_rounds=None, enable_categorical=False,\n",
      "              eval_metric=None, feature_types=None, gamma=None,\n",
      "              grow_policy='lossguide', importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.399189341291266,\n",
      "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=0, max_leaves=6,\n",
      "              min_child_weight=3.4353192705502913, missing=nan,\n",
      "              monotone_constraints=None, multi_strategy=None, n_estimators=46,\n",
      "              n_jobs=-1, num_parallel_tree=None, objective='multi:softprob', ...)\n",
      "[flaml.automl.logger: 03-23 15:37:56] {1985} INFO - fit succeeded\n",
      "[flaml.automl.logger: 03-23 15:37:56] {1986} INFO - Time taken to find the best model: 42.68849301338196\n"
     ]
    }
   ],
   "source": [
    "\n",
    "auto_ml = AutoML()\n",
    "\n",
    "# Set up AutoML configuration\n",
    "settings = {\n",
    "    \"time_budget\": 60,  # Time budget in seconds\n",
    "    \"metric\": 'accuracy',  # Use F1 score as the metric\n",
    "    \"task\": 'classification',  # Classification task\n",
    "    \"log_file_name\": \"automl.log\",  # Optional log file for debugging\n",
    "    \"estimator_list\": [\"xgboost\",\"rf\",\"extra_tree\",\"xgb_limitdepth\",\"sgd\",\"catboost\",\"lrl1\"]  # Specify models\n",
    "}\n",
    "#[\"xgboost\",\"rf\",\"extra_tree\",\"xgb_limitdepth\",\"sgd\",\"catboost\",\"lrl1\"]\n",
    "\n",
    "# Train AutoML model\n",
    "auto_ml.fit(X_train=X_train, y_train=y_train, **settings)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = auto_ml.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = f1_score(y_test, y_pred,average='weighted')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9550158118584249\n"
     ]
    }
   ],
   "source": [
    "print(\"F1-Score\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<flaml.automl.model.XGBoostSklearnEstimator object at 0x35b7e72c0>\n"
     ]
    }
   ],
   "source": [
    "print(auto_ml.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 46, 'max_leaves': 6, 'min_child_weight': 3.4353192705502913, 'learning_rate': 0.399189341291266, 'subsample': 0.903512345912589, 'colsample_bylevel': 0.7563793731764131, 'colsample_bytree': 0.7647693832410042, 'reg_alpha': 0.03542523638424809, 'reg_lambda': 0.10434057752736216, 'n_jobs': -1, 'max_depth': 0, 'grow_policy': 'lossguide', 'tree_method': 'hist', 'verbosity': 0, 'task': <flaml.automl.task.generic_task.GenericTask object at 0x3398030b0>, '_estimator_type': 'classifier'}\n"
     ]
    }
   ],
   "source": [
    "best_model = auto_ml.model\n",
    "best_params = best_model.get_params() if hasattr(best_model, 'get_params') else \"No parameters available\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Parameters:\n",
      "n_estimators: 46\n",
      "max_leaves: 6\n",
      "min_child_weight: 3.4353192705502913\n",
      "learning_rate: 0.399189341291266\n",
      "subsample: 0.903512345912589\n",
      "colsample_bylevel: 0.7563793731764131\n",
      "colsample_bytree: 0.7647693832410042\n",
      "reg_alpha: 0.03542523638424809\n",
      "reg_lambda: 0.10434057752736216\n",
      "n_jobs: -1\n",
      "max_depth: 0\n",
      "grow_policy: lossguide\n",
      "tree_method: hist\n",
      "verbosity: 0\n",
      "task: multiclass\n",
      "_estimator_type: classifier\n"
     ]
    }
   ],
   "source": [
    "# Print the best model parameters one by one\n",
    "if best_params:\n",
    "    print(\"Best Model Parameters:\")\n",
    "    for param, value in best_params.items():\n",
    "        print(f\"{param}: {value}\")\n",
    "else:\n",
    "    print(\"No parameters available for the best model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
